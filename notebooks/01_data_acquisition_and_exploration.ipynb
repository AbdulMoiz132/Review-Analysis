{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631f3900",
   "metadata": {},
   "source": [
    "# Step 1: Data Acquisition and Exploration\n",
    "\n",
    "This notebook covers the first step of our sentiment analysis project:\n",
    "- Setting up the environment\n",
    "- Loading the IMDB dataset\n",
    "- Basic data exploration\n",
    "- Understanding the dataset structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04027d3",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For text processing\n",
    "import re\n",
    "import string\n",
    "\n",
    "# NLTK for natural language processing\n",
    "import nltk\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562f6da",
   "metadata": {},
   "source": [
    "## Download NLTK Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "print(\"NLTK data downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d947d",
   "metadata": {},
   "source": [
    "## Load and Explore IMDB Dataset\n",
    "\n",
    "We'll use the built-in IMDB dataset from scikit-learn for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Actually, let's create a sample dataset since scikit-learn doesn't have IMDB\n",
    "# We'll create a simple dataset for demonstration\n",
    "\n",
    "# Sample movie reviews data\n",
    "sample_reviews = [\n",
    "    \"This movie was absolutely fantastic! Great acting and storyline.\",\n",
    "    \"Terrible movie, waste of time. Poor acting and boring plot.\",\n",
    "    \"Amazing film with incredible visuals and outstanding performances.\",\n",
    "    \"Worst movie I've ever seen. Complete disaster.\",\n",
    "    \"Loved every minute of it! Highly recommended for everyone.\",\n",
    "    \"Disappointing film with weak characters and poor direction.\",\n",
    "    \"Excellent movie with great cinematography and compelling story.\",\n",
    "    \"Boring and predictable. Not worth watching.\",\n",
    "    \"Outstanding performances by all actors. Must watch!\",\n",
    "    \"Complete waste of money. Avoid at all costs.\"\n",
    "]\n",
    "\n",
    "sample_labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'review': sample_reviews,\n",
    "    'sentiment': sample_labels\n",
    "})\n",
    "\n",
    "print(\"Sample dataset created successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fb3c4",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Number of reviews: {len(df)}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sentiment distribution\n",
    "print(\"Sentiment Distribution:\")\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "print(sentiment_counts)\n",
    "print(\"\\nSentiment Distribution (%):\") \n",
    "print(df['sentiment'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualize sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.xlabel('Sentiment (0=Negative, 1=Positive)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1be44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine sample reviews\n",
    "print(\"Sample Positive Reviews:\")\n",
    "positive_reviews = df[df['sentiment'] == 1]['review'].head(3)\n",
    "for i, review in enumerate(positive_reviews, 1):\n",
    "    print(f\"{i}. {review}\")\n",
    "\n",
    "print(\"\\nSample Negative Reviews:\")\n",
    "negative_reviews = df[df['sentiment'] == 0]['review'].head(3)\n",
    "for i, review in enumerate(negative_reviews, 1):\n",
    "    print(f\"{i}. {review}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset for future use\n",
    "df.to_csv('../data/sample_reviews.csv', index=False)\n",
    "print(\"Dataset saved to '../data/sample_reviews.csv'\")\n",
    "\n",
    "# Display dataset summary\n",
    "print(\"\\n=== STEP 1 COMPLETED ===\")\n",
    "print(\"✓ Environment setup complete\")\n",
    "print(\"✓ Sample dataset created and loaded\")\n",
    "print(\"✓ Basic data exploration completed\")\n",
    "print(\"✓ Dataset saved for next steps\")\n",
    "print(\"\\nNext: Data preprocessing and text cleaning\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
